<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Barbaros Voice Test</title>
  <link rel="stylesheet" href="voice-test-client.css">
</head>
<body>
  <div class="container">
    <h1>Barbaros Voice Test</h1>
    
    <div class="panel">
      <div id="connectionStatus" class="connection-status">Connecting to voice server...</div>
      <button id="startButton">Start Listening</button>
      <div id="recordingIndicator" class="recording-indicator">Recording...</div>
    </div>
    
    <div class="status">
      <div class="status-box">
        <h3>Wake Word</h3>
        <div id="wakeWordStatus">Not detected</div>
      </div>
      
      <div class="status-box">
        <h3>Transcription</h3>
        <div id="transcriptionStatus">Say something after wake word</div>
      </div>
      
      <div class="status-box">
        <h3>Command</h3>
        <div id="commandStatus">No command detected</div>
      </div>
    </div>
    
    <div class="panel">
      <h3>Command Log</h3>
      <div id="commandLog" class="log"></div>
    </div>
  </div>

  <!-- Simple audio elements -->
  <audio id="wakeWordSound" src="data:audio/wav;base64,UklGRigBAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQQBAADpAFgBpQIPA64DTAWdBv0HewkhCndKSkRAPTg2LCknJCAgHRkaGBYWFBMTERAPDw0NDAsLCgoKCQkICAcHBwYGBgYFBQUFBAQEBAQDAwMDAwMDAwMCAgICAgICAgICAgICAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=" preload="auto"></audio>
  <audio id="intentSound" src="data:audio/wav;base64,UklGRigBAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQQBAACFAFgAhACpAPcAewLpAYIABwCb/3X+gf+6AG8CRwX3BVsG8gbmBvYFDQZwBZgEBAT1Ag0CnwFvAGn/kf6P/t/+1P4XAK0AiQFHAp0CvQIPA8QCLQKfAan+O/6V/z3+dv4P/0QAWQFxA8cE6AM1A30CWQGkAM7/lP6o/sr+3f4tAEABrQJ+A3cE8gS4BAoEngOoArEBcADz/5X/9v6v/qT+Kv8X/4UA0wEXA7kE6QW1BgoIuQjNCM0IiQipBREF1QMDAu3/Uf6x/W/8nvsD+6n6uPpp+pP6F/uL++H7EvxO/L78mvwK/FT7ifrM+a/5HPq0+ip8zX14fvB/noGQg4yFaYcHibKK0IuwjAKNOI3MjCyMO4s=" preload="auto"></audio>

  <script>
    // DOM elements
    const startButton = document.getElementById('startButton');
    const recordingIndicator = document.getElementById('recordingIndicator');
    const wakeWordStatus = document.getElementById('wakeWordStatus');
    const transcriptionStatus = document.getElementById('transcriptionStatus');
    const commandStatus = document.getElementById('commandStatus');
    const commandLog = document.getElementById('commandLog');
    const wakeWordSound = document.getElementById('wakeWordSound');
    const intentSound = document.getElementById('intentSound');
    const connectionStatus = document.getElementById('connectionStatus');
    
    // Global variables
    let ws;
    let isListening = false;
    let audioContext;
    let audioStream;
    let recorder;
    
    // Initialize WebSocket
    function initWebSocket() {
      connectionStatus.textContent = "Connecting to voice server...";
      connectionStatus.className = "connection-status";
      
      ws = new WebSocket('ws://localhost:9000/mic');
      
      ws.onopen = function() {
        console.log('Connected to voice server');
        connectionStatus.textContent = "Connected to voice server - Auto-starting...";
        connectionStatus.className = "connection-status connected";
        
        // Auto-start listening when connected
        if (!isListening) {
          toggleListening();
        }
        
        if (audioContext) {
          // Send sample rate
          ws.send(audioContext.sampleRate.toString());
        }
      };
      
      ws.onclose = function() {
        console.log('Disconnected from voice server');
        connectionStatus.textContent = "Disconnected from voice server - Reconnecting...";
        connectionStatus.className = "connection-status error";
        
        // Update UI state if we were listening
        if (isListening) {
          isListening = false;
          startButton.classList.remove('listening');
          startButton.textContent = 'Start Listening';
          recordingIndicator.classList.remove('active');
        }
        
        // Try to reconnect after a delay
        setTimeout(initWebSocket, 3000);
      };
      
      ws.onerror = function(error) {
        console.error('WebSocket error:', error);
        connectionStatus.textContent = "Connection error - check if server is running";
        connectionStatus.className = "connection-status error";
      };
      
      ws.onmessage = function(event) {
        try {
          const message = JSON.parse(event.data);
          
          // Process different message types
          switch(message.type) {
            case 'models':
              console.log('Available models:', message.data);
              break;
              
            case 'activations':
              handleWakeWordDetection(message.data);
              break;
              
            case 'transcription':
              handleTranscription(message.data);
              break;
              
            case 'intent':
              handleIntent(message.data);
              break;
              
            default:
              console.log('Received unknown message type:', message);
          }
        } catch (error) {
          console.error('Error processing message:', error);
        }
      };
    }
    
    // Handle wake word detection
    function handleWakeWordDetection(activations) {
      wakeWordStatus.textContent = `Detected: ${activations.join(', ')}`;
      recordingIndicator.textContent = "Recording... 4";
      recordingIndicator.classList.add('active');
      
      // Start countdown timer (4 seconds)
      startCountdown(4);
      
      // Log the wake word detection
      addLogEntry(`Wake word detected: ${activations.join(', ')}`);
    }
    
    // Countdown timer function
    function startCountdown(seconds) {
      const interval = setInterval(() => {
        seconds--;
        if (seconds > 0) {
          recordingIndicator.textContent = `Recording... ${seconds}`;
        } else {
          clearInterval(interval);
          recordingIndicator.textContent = "Recognizing speech...";
        }
      }, 1000);
    }
    
    // Handle transcription
    function handleTranscription(text) {
      transcriptionStatus.textContent = text;
      recordingIndicator.classList.remove('active');
      
      // Log the transcription
      addLogEntry(`Transcription: ${text}`);
    }
    
    // Handle intent recognition
    function handleIntent(intent) {
      let commandText = 'Unknown command';
      
      if (intent.command && intent.command !== 'unknown') {
        if (intent.value !== undefined) {
          commandText = `${formatCommand(intent.command)} (${intent.value})`;
        } else {
          commandText = formatCommand(intent.command);
        }
      }
      
      commandStatus.textContent = commandText;
      
      // Log the intent
      addLogEntry(`Command: ${commandText}`);
    }
    
    // Format command for display
    function formatCommand(command) {
      return command
        .split('_')
        .map(word => word.charAt(0).toUpperCase() + word.slice(1))
        .join(' ');
    }
    
    // Add entry to command log
    function addLogEntry(text) {
      const entry = document.createElement('div');
      entry.className = 'log-entry';
      entry.textContent = `[${new Date().toLocaleTimeString()}] ${text}`;
      
      commandLog.insertBefore(entry, commandLog.firstChild);
      
      // Limit log entries
      while (commandLog.children.length > 50) {
        commandLog.removeChild(commandLog.lastChild);
      }
    }
    
    // Initialize audio capture
    function initAudioCapture() {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(function(stream) {
          audioStream = stream;
          
          // Create audio context
          const AudioContext = window.AudioContext || window.webkitAudioContext;
          audioContext = new AudioContext();
          
          // Get sample rate
          const sampleRate = audioContext.sampleRate;
          console.log('Sample rate:', sampleRate);
          
          // Send sample rate to server
          if (ws && ws.readyState === WebSocket.OPEN) {
            ws.send(sampleRate.toString());
          }
          
          // Create script processor
          const bufferSize = 4096;
          recorder = audioContext.createScriptProcessor(bufferSize, 1, 1);
          
          // Create media stream source
          const source = audioContext.createMediaStreamSource(stream);
          
          // Set up audio processing
          recorder.onaudioprocess = function(event) {
            if (!isListening) return;
            
            const samples = event.inputBuffer.getChannelData(0);
            const pcm16Samples = Int16Array.from(samples.map(sample => {
              let val = Math.floor(32767 * sample);
              return Math.min(32767, Math.max(-32768, val));
            }));
            
            // Send audio data to server
            if (ws && ws.readyState === WebSocket.OPEN) {
              ws.send(pcm16Samples.buffer);
            }
          };
          
          // Connect the nodes
          source.connect(recorder);
          recorder.connect(audioContext.destination);
          
          console.log('Audio capture initialized');
        })
        .catch(function(error) {
          console.error('Error initializing audio capture:', error);
          addLogEntry(`Error: ${error.message}`);
        });
    }
    
    // Toggle listening state
    function toggleListening() {
      if (!isListening) {
        // Start listening
        isListening = true;
        startButton.classList.add('listening');
        startButton.textContent = 'Stop Listening';
        
        // Initialize audio capture if needed
        if (!audioContext) {
          initAudioCapture();
        }
        
        // Ensure WebSocket is connected
        if (!ws || ws.readyState !== WebSocket.OPEN) {
          initWebSocket();
        } else {
          // Send listening status
          ws.send("start_listening");
        }
        
        connectionStatus.textContent = "Listening for wake word...";
        connectionStatus.className = "connection-status connected";
        
        addLogEntry('Started listening');
      } else {
        // Stop listening
        isListening = false;
        startButton.classList.remove('listening');
        startButton.textContent = 'Start Listening';
        recordingIndicator.classList.remove('active');
        
        // Send listening status
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send("stop_listening");
        }
        
        connectionStatus.textContent = "Listening paused";
        connectionStatus.className = "connection-status";
        
        addLogEntry('Stopped listening');
      }
    }
    
    // Set up event listeners
    startButton.addEventListener('click', toggleListening);
    
    // Initialize WebSocket connection
    initWebSocket();
  </script>
</body>
</html>